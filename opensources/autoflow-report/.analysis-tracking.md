---
stepsCompleted: [1, 2, 3]
completed: true
projectName: "autoflow"
projectUrl: "https://github.com/pingcap/autoflow"
codebaseRef: "/home/hieutt50/projects/awesome-agentic-solutions/autoflow"
started: "2025-12-27"
lastStep: "Report Generation"
analysisCompleted: "2025-12-27"
reportsGenerated: "2025-12-27"
---

# Analysis Tracking: autoflow

This file tracks the progress of the opensource codebase analysis workflow.

## Project Information

- **Project Name**: autoflow
- **Project URL**: https://github.com/pingcap/autoflow
- **Codebase Reference**: /home/hieutt50/projects/awesome-agentic-solutions/autoflow
- **Started**: 2025-12-27
- **Status**: Complete

## Analysis Progress

- [x] Step 1: Initialization (inputs gathered, workspace created)
- [x] Step 2: Codebase Analysis
- [x] Step 3: Report Generation

---

## Workflow Complete

All analysis steps have been successfully completed:

- [x] Step 1: Initialization
- [x] Step 2: Codebase Analysis
- [x] Step 3: Report Generation

**Reports Generated:**
- `overview.md` - Quick summary with key insights
- `detailed-report.md` - Comprehensive technical analysis

**Completion Date**: 2025-12-27

---

## Analysis Findings

### Project Metadata

**Repository Information:**
- GitHub Stars: 2.7k
- Forks: 168
- Watchers: 24
- Contributors: 18
- License: Apache-2.0
- Latest Release: v0.4.0 (January 3, 2025)

**Primary Languages:**
- TypeScript: 52.8%
- Python: 41.9%
- Jupyter Notebook: 3.8%

**Project Description:**
Graph RAG based and conversational knowledge base tool built with TiDB Serverless Vector Storage. Features Perplexity-style conversational search and embeddable JavaScript widget.

**Status:** Early-stage development with plans to become a Python package installable via pip.

**Live Demo:** https://tidb.ai

---

### Technology Stack

#### Programming Languages
- **Python** 3.10+ (~50%): Backend services, RAG framework, AI/ML logic, core library
- **TypeScript** 5.7.2 (~40%): Frontend application, React components, UI logic
- **JavaScript**: Node.js runtime, package management, build tooling

#### Frontend Technologies
- **Framework:** Next.js 15.1.11, React 19.0.0
- **UI Libraries:** shadcn/ui, Radix UI (v1.1-v2.2), Lucide Icons
- **Styling:** Tailwind CSS 3.4.16, PostCSS, Sass
- **State Management:** React Query (SWR) 2.2.5, Zustand
- **Data Visualization:** Recharts, D3.js, Force-graph
- **Text Processing:** Unified, Remark, Rehype, Monaco Editor
- **Animations:** Framer Motion 11.18.2
- **Testing:** Jest 29.7.0, Playwright 1.46.0, Testing Library
- **Package Manager:** pnpm 9.15.0

#### Backend Technologies
- **Web Framework:** FastAPI 0.115.6, Uvicorn, Gunicorn
- **ORM:** SQLModel 0.0.19, Alembic (migrations)
- **Validation:** Pydantic 2.10.5
- **Database Drivers:** PyMySQL, AsyncMy, TiDB Vector 0.0.14
- **Task Queue:** Celery 5.4.0, Flower (monitoring)
- **Caching:** Redis 5.0.5
- **Authentication:** FastAPI Users 13.0.0, HTTPx OAuth

#### Database & Storage
- **TiDB Vector** 0.0.14 - Distributed SQL database with vector support
- **Redis** 6.0.16 - In-memory cache and session store
- **Vector Storage:** Integrated with TiDB for semantic search

#### AI/ML Frameworks
**RAG Framework:**
- LlamaIndex 0.12.16+ - Core RAG components
- DSPy 2.6.21+ - LLM programming framework
- LiteLLM 1.67.4+ - Unified LLM API

**LLM Providers:**
- OpenAI, Azure OpenAI, Google Gemini, Vertex AI
- Bedrock, Ollama, OpenAI-like endpoints

**Embedding Providers:**
- Jina AI, Cohere, Bedrock, Azure OpenAI, Ollama
- Sentence Transformers (local option)

**Reranking Providers:**
- Jina AI, Cohere, Bedrock, Xinference
- Local sentence-transformers

**Observability:**
- Langfuse 2.59.1 - LLM observability
- Sentry SDK 2.5.1 - Error tracking

**Evaluation:**
- RAGAS 0.2.6 - RAG evaluation
- DeepEval 0.21.73 - LLM evaluation

#### Development Tools
- **Testing:** pytest, pytest-asyncio, Jest, Playwright
- **Linting:** Ruff 0.11.2 (Python), ESLint (JavaScript)
- **Type Checking:** MyPy, Pyright, TypeScript
- **Document Processing:** Playwright (web scraping), PyPDF, python-docx, python-pptx, openpyxl

#### Infrastructure & Deployment
- **Containerization:** Docker, Docker Compose
- **CI/CD:** GitHub Actions (testing, linting, E2E regression, releases)
- **Process Management:** Supervisord (multi-process in containers)
- **Monitoring:** Sentry, Langfuse, Flower dashboard

---

### Architecture Analysis

#### Overall Architecture Style
**Modular Monolith** with clear separation:
- FastAPI Python backend (monolithic API server)
- Next.js TypeScript frontend (Single Page Application)
- Standalone `autoflow-ai` core library (Python package)

#### Component Structure

**Backend (FastAPI):**
- REST API with public and admin routes
- Repository pattern for data access layer
- Service layer (ChatFlow, ChatService, RAGService)
- RAG pipeline with multiple retrieval modes
- Celery + Redis for async background tasks

**Core Library (autoflow-ai):**
- KnowledgeBase abstraction
- Knowledge graph extraction and retrieval
- Pluggable document loaders and chunkers
- Abstract storage interfaces (VectorStore, GraphStore)

**Frontend (Next.js):**
- React Server Components architecture
- Feature-based organization
- Context API + SWR for state management
- Complete TypeScript API client SDK
- Embeddable widget component

#### Design Patterns
1. **Repository Pattern** - Data access abstraction
2. **Factory Pattern** - Model creation (LLMs, embeddings, rerankers)
3. **Strategy Pattern** - Pluggable providers
4. **Adapter Pattern** - Storage backend abstraction
5. **Service Layer** - Business logic encapsulation
6. **Dependency Injection** - FastAPI dependencies

#### Code Organization
- **Backend:** Modular by feature (api/, rag/, repositories/, models/)
- **Frontend:** Feature-based organization with shared components
- **Core:** Library pattern with clear public API

#### API Design
- RESTful API with FastAPI
- OpenAPI/Swagger documentation
- JWT-based authentication
- Server-Sent Events (SSE) for streaming responses
- Pagination support via fastapi-pagination

#### Data Flow

**Chat Completion Flow:**
1. User query → API endpoint
2. RAG retrieval (vector search + graph traversal)
3. LLM synthesis with context
4. SSE streaming response to frontend

**Document Ingestion Flow:**
1. File/URL upload → API endpoint
2. Document chunking → Embedding generation
3. Vector storage + Knowledge graph extraction
4. Background processing via Celery

**Retrieval Modes:**
- Vector search only
- Knowledge graph traversal
- Fusion (vector + graph combined)
- Metadata filtering

#### Integration Points
- Backend ↔ Core library (dual use pattern)
- Celery async tasks for document processing
- TiDB Vector for hybrid search (SQL + vector)
- External providers (OpenAI, JinaAI, LiteLLM)
- Langfuse for observability

---

### Use Cases

#### Main Problem Solved
AutoFlow solves the **knowledge discovery and customer support problem** for organizations with large documentation repositories. It transforms static documentation sites into conversational, AI-powered search interfaces where users can ask natural language questions and receive context-aware answers backed by a knowledge graph.

#### Primary Use Cases

1. **Product Documentation Chatbots for SaaS/APIs**
   - Companies with extensive API or product documentation deploy AutoFlow to provide instant conversational support on their docs sites
   - Users ask natural language questions instead of navigating nested documentation menus
   - Embeddable widget integrates seamlessly into existing websites

2. **In-Product Customer Support Widget**
   - SaaS and service companies embed the widget to field common product questions 24/7
   - Handles FAQs, pricing questions, feature explanations, and troubleshooting automatically
   - Reduces support ticket volume

3. **Knowledge Base Construction for Enterprise Systems**
   - Organizations build internal knowledge bases from technical documentation, wikis, and policy documents
   - Graph RAG approach enables search across multiple documents and relationships
   - Improves institutional knowledge accessibility

4. **Educational Platform Q&A System**
   - Course platforms use AutoFlow to build conversational learning assistants
   - Answers student questions about course materials, assignments, and prerequisites
   - Indexes lecture notes, textbooks, and FAQs

5. **Technical Documentation Exploration Tool**
   - Open-source projects use AutoFlow to make documentation more discoverable
   - Perplexity-style interface for natural conversations with documentation
   - Example: https://tidb.ai for TiDB documentation

#### Target User Personas
1. **Product Managers / Documentation Teams** at SaaS companies
2. **Enterprise Knowledge Management Teams**
3. **Open Source Project Maintainers**
4. **AI/ML Engineers** building RAG applications
5. **Developer Tool and API Providers**

#### Common Application Scenarios
- JavaScript widget embedded on website footer
- Dedicated chat interface at custom domain
- Multi-knowledge base setup for different products
- Automated documentation crawling via sitemap URLs
- API integration for programmatic access
- Evaluation/QA pipeline for response quality testing

#### Industry/Domain Applicability
- **High Applicability:** Technology/Software, SaaS/Cloud Platforms, Education
- **Medium Applicability:** Healthcare Tech, Finance/FinTech, E-commerce
- **Best Fit:** Industries with high documentation volume + large support costs + technical audiences

#### Typical Deployment Contexts
1. **Full-Stack SaaS Deployment** - Self-hosted on company infrastructure
2. **Embedded Widget Model** - Core infrastructure + JavaScript widget on public website
3. **Self-Hosted RAG Framework** - Python package integration into custom applications
4. **Open Source Community Deployment** - Publicly accessible documentation chatbot
5. **Evaluation and Testing Environment** - A/B testing and quality measurement

---

### Evaluation

#### Strengths (Pros)

**Technical Advantages:**
- **Graph RAG Architecture**: Dual-index approach combining vector search and knowledge graphs for richer semantic understanding
- **Multi-hop Relationships**: Graph traversal enables queries beyond simple semantic search
- **TiDB Integration**: Native SQL + vector storage in single database, eliminates separate vector DB infrastructure
- **Flexible LLM/Embedding Support**: 7+ LLM providers, multiple embedding models, 4 reranking options
- **Data Source Flexibility**: Web crawler, sitemap scraping, multiple file formats (PDF, DOCX, PPTX, XLSX)
- **Local Options**: Self-hosted embedding/reranker for data privacy
- **Query Intelligence**: Query decomposition, semantic caching, metadata filtering

**Developer Experience:**
- Well-organized modular codebase with clear separation of concerns
- Type hints throughout (Python 3.10+) with Pydantic v2
- Docker Compose configurations for dev and production
- Pre-configured Redis + Celery for async tasks
- Minimal resource requirements (4 CPU cores, 8GB RAM initial deployment)

**Community & Ecosystem:**
- Actively maintained (v0.4.0, December 2024)
- 2.7k GitHub stars, 168 forks, 18 contributors
- Apache 2.0 license (production-friendly)
- Live demo at tidb.ai
- Responsive core maintainers

**Performance Characteristics:**
- Fusion retrieval combines results across multiple knowledge bases
- Configurable graph traversal depth
- Reranking pipeline improves answer quality
- Semantic cache eliminates redundant LLM calls
- TiDB's distributed architecture supports horizontal scaling

#### Weaknesses (Cons)

**Technical Limitations:**
- **No Async/Await**: Zero async implementations in chat/retrieval modules limits concurrent request handling
- **Knowledge Graph Extraction Overhead**: DSPy-based extraction requires separate LLM calls per chunk, significantly slowing indexing
- **Limited Testing**: Only 16 test files across 331 Python files; minimal coverage of core RAG modules
- **Limited Graph Query Capabilities**: Fixed depth-based traversal; no path-finding algorithms
- **Error Handling Issues**: Multiple FIXME comments; limited exception hierarchy

**Learning Curve:**
- **Steep Setup**: Requires TiDB, Redis, multiple microservices
- **Complex Architecture**: 5-layer architecture (datasource → parser → embedder → indexer → retriever)
- **DSPy Patterns**: Unfamiliar to most developers
- **Limited Documentation**: Only 2,705 lines across project; no architectural diagrams; limited examples

**Potential Issues:**
- **Performance Bottlenecks**: Graph extraction adds 2-3x latency per document; synchronous chat flow limits throughput
- **Scalability Concerns**: Every chat query triggers vector search + graph traversal; high LLM costs during indexing
- **Production Readiness**: No multi-tenancy; access control marked as FIXME; semantic cache in beta
- **API Rate Limits**: No built-in rate limiting or retry logic

**Ecosystem Gaps:**
- No streaming vector store (all results loaded into memory)
- No hybrid search (BM25 + vector) despite TiDB SQL support
- Limited to TiDB Vector (no Pinecone, Weaviate, OpenSearch support)
- No multimodal support (text-only)
- No built-in monitoring UI (Langfuse integration exists but no dashboard)
- No cost estimation tools for API usage

#### Performance Considerations

**Scalability:**
- TiDB scales horizontally; vector index distributed
- Stateless FastAPI instances can scale with load balancer
- Celery allows distributed task processing
- **Limitation**: Single instance likely handles 50-100 concurrent users before degradation due to synchronous processing

**Resource Requirements:**
- **Minimum Production:** 8-20 CPU cores, 22-50GB RAM total
- **Backend:** 2-4 cores, 4-8GB RAM
- **TiDB:** 2-8 cores, 8-16GB RAM (needs clustering)
- **Redis:** 1 core, 1-2GB RAM
- **Embedding Service:** 2-4 cores, 8-16GB RAM (if using local models)

**Known Bottlenecks:**
1. Knowledge graph extraction: 10 documents = 2-5 minutes (LLM-dependent)
2. Vector search + graph traversal: P95 latency 2-5 seconds for complex queries
3. Synchronous I/O limits request throughput
4. External rerankers add 500ms-2s per request
5. No LLM provider failover

---

### Alternatives

#### 1. RAGFlow (70.3k GitHub Stars)

**Description:** Enterprise-grade RAG engine with deep document understanding, graph-based knowledge extraction, and agentic capabilities.

**Similarities:**
- Graph-based RAG approach
- Multi-format document support
- Open-source with self-hosting option

**Key Differences:**
- Much larger scale focus (enterprise data pipelines)
- 40+ data connectors vs AutoFlow's crawler focus
- Built-in agentic capabilities
- More mature (70k stars vs 2.7k)

**When to Choose:** Need enterprise-grade data connectors, processing large volumes of diverse documents, or require agentic workflows.

**Popularity/Maturity:** 70.3k stars, backed by InfiniFlow, more mature

---

#### 2. Onyx/Danswer (12.1k GitHub Stars)

**Description:** Enterprise search platform with 40+ data connectors, hybrid search, fine-grained access control, and Slack integration.

**Similarities:**
- RAG-based search
- Multi-source knowledge aggregation
- Self-hosted option

**Key Differences:**
- Enterprise-first with RBAC and multi-tenancy
- 40+ native connectors (Google Drive, Confluence, etc.)
- $10M funding, commercial backing
- More complex deployment

**When to Choose:** Large organizations needing unified search across multiple data sources with strong access control.

**Popularity/Maturity:** 12.1k stars, $10M Series A funding, production-ready

---

#### 3. Quivr (37k-38.7k GitHub Stars)

**Description:** Flexible RAG framework with multi-LLM support, easy integration, and second-brain philosophy.

**Similarities:**
- RAG framework
- Multi-LLM support
- Open-source

**Key Differences:**
- More flexible/generic (not docs-focused)
- Personal knowledge management angle
- Easier integration into existing products
- Less opinionated architecture

**When to Choose:** Building custom RAG applications, need maximum flexibility, or personal knowledge management use case.

**Popularity/Maturity:** 37k-38.7k stars, very active community, mature

---

#### 4. Perplexica (10k+ GitHub Stars)

**Description:** Privacy-focused open-source alternative to Perplexity AI with web search and local LLM support.

**Similarities:**
- Perplexity-style conversational interface
- Local LLM support
- Open-source

**Key Differences:**
- Web search focused (not documentation)
- Real-time web scraping vs indexed knowledge base
- Privacy-first design
- No knowledge graph

**When to Choose:** Need web search capabilities with privacy, Perplexity alternative, or real-time information needs.

**Popularity/Maturity:** 10k+ stars, active development, focused on web search

---

#### 5. Khoj (10k+ GitHub Stars)

**Description:** Multimodal AI assistant with cross-platform availability (mobile, WhatsApp, Obsidian, Emacs, desktop).

**Similarities:**
- Conversational AI
- Multi-source knowledge
- Self-hosted option

**Key Differences:**
- Personal assistant focus (not enterprise docs)
- Multimodal (text, images, voice)
- Cross-platform (mobile, chat apps, desktop)
- Automation capabilities

**When to Choose:** Personal or team AI assistant, multimodal needs, or deep integration with productivity tools.

**Popularity/Maturity:** 10k+ stars, active community, production-ready

---

### AutoFlow's Unique Position

AutoFlow stands out with its combination of:
- **Graph RAG + Embeddable Widget** specialized for documentation search
- **Lighter deployment** compared to enterprise competitors
- **TiDB-native** vector storage integration
- **Early-stage flexibility** for customization

**Trade-off:** Lower market traction (2.7k stars) vs pure frameworks (Quivr: 37k) and enterprise solutions (RAGFlow: 70k).

---

### Code Quality Observations

**Positives:**
- Clean modular architecture with clear separation of concerns
- Type hints throughout Python codebase (Python 3.10+)
- Pydantic v2 for data validation
- Comprehensive linting with Ruff and ESLint
- Docker-based deployment with CI/CD

**Concerns:**
- Minimal test coverage (16 test files for 331 Python files)
- Multiple FIXME/TODO comments in critical paths
- No async/await patterns despite using FastAPI
- Limited error handling in some modules
- Undocumented performance characteristics

---

### Community and Maintenance

**Activity Metrics:**
- 18 contributors, 5 core maintainers
- Latest release: v0.4.0 (January 3, 2025)
- Active GitHub Issues and Discussions
- Discord community available

**Maintenance Status:**
- Early-stage development (v0.4.0)
- Plans to become pip-installable Python package
- Actively working toward productionization
- Responsive maintainer team

**Ecosystem Health:**
- Growing star count (2.7k)
- 168 forks indicate community interest
- Apache 2.0 license enables commercial use
- Live production deployment at tidb.ai demonstrates viability

**Community Resources:**
- Documentation site: https://autoflow.tidb.ai
- Contributing guidelines available
- Discord for support
- GitHub Discussions for Q&A

---

## Summary

AutoFlow is a **well-architected Graph RAG platform** with strong technical foundations in multi-provider LLM/embedding support, flexible data ingestion, and TiDB integration. The dual vector/graph indexing approach is sophisticated and suitable for knowledge-intensive applications.

**Best suited for:**
- Documentation-focused knowledge bases
- Organizations using TiDB infrastructure
- Projects requiring offline/local embedding capabilities
- Medium-scale deployments (1-10M documents)

**Caution areas:**
- Early-stage project (v0.4.0) with minimal test coverage
- Synchronous architecture limits high-concurrency scenarios
- Graph extraction overhead requires careful indexing strategy
- Steeper operational setup with multiple services

**Recommendation:** Evaluate for knowledge-intensive documentation use cases; plan for async refactoring if high concurrency is required. Monitor performance under specific data/query volumes before production deployment.
